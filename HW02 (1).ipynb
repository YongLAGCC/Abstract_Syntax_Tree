{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Two:  Context-Free Grammars and Shift-Reduce Parsing\n",
    "\n",
    "Please provide answers to these problems by filling in this notebook and submitting it via websubmit by Tuesday 2/6 by midnight.  For the second problem, you must also submit an electronic version of your drawings, either using drawing software or by scanning or photographing hand drawings. Make sure in the latter case that the result is legible; if we can not understand your drawing, it will receive no credit. \n",
    "\n",
    "You may submit by Wednesday midnight for a 20% penalty; after that no credit will be given. \n",
    "\n",
    "I will drop the lowest homework/lab combination at the end of the term.\n",
    "\n",
    "For coding problems any <i> reasonable </i> solution, in which you understand the spirit of the exercise and try to learn this week's material through your efforts, will be graded based solely on the test cases. In general, shortcuts to avoid learning the material will be unreasonable. For example, you may not use any Python libraries or functions that make your task dramatically easier (e.g., you may use split(), replace(...), int(...), and float(...), as mentioned below, and any other normal functions, but may NOT use the Python library for regular expressions).  Good Python style, using list comprehensions, Numpy, creating helper functions in addition to what is required, etc., <i>when appropriate,</i> are quite reasonable! Check with me if you have questions about this. \n",
    "\n",
    "<b> Make sure to click Cell -> Run All before submitting notebooks!!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem One (10 pts)\n",
    "\n",
    "Give context-free grammars for the following languages. \n",
    "<ol style=\"list-style-type: lower-alpha;\">\n",
    "      <li>The language of matching delimiters over the alphabet: <pre>\n",
    "      {    }    [    ]    (    )        \n",
    "</pre>   \n",
    "   \n",
    "   the following are in the language:  <code>   (())    ({})    {([]())}{}</code> <br>\n",
    "   the following are not:   <code>   ({)}   {{{}})  </code>  $\\epsilon$ (empty string)<br>\n",
    "\n",
    "</li>      \n",
    "      <li> The language $\\{ a^n b^m a^n |\\, n \\ge 0 \\text{ and } m > 1 \\}$\n",
    "      <li> The language represented by the regular expression $a\\, b^\\ast\\, (\\,c\\,|\\,d\\,)$.\n",
    "      <li> The language over $\\{ a,b\\}$ of strings with an odd number of a's and any number of b's. \n",
    "      <li>The language over alphabet $\\{a,b\\}$ where the number of $a$'s = the number of $b$'s (any length, including 0). \n",
    "</ol>\n",
    "Hint: For c and d, the languages are regular: simulate a DFA by associating a non-terminal with each state, and then write rules which make \"transitions\" from one state to another; each rule will have a single non-terminal in the last position on the right-hand side. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "<pre>\n",
    "Your answer here\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Two (5 pts)\n",
    "\n",
    "This is a problem showing how difficult it sometimes is to create non-ambiguous grammars for standard programming language constructs. It is called the \"dangling else problem.\"\n",
    "\n",
    "(a) Show that the following obvious grammar for conditional statements is ambiguous by showing\n",
    "two different parse trees for the input <code> if expr then if expr then stmt else stmt</code>.      \n",
    "<pre>   \n",
    "     S := if expr then S\n",
    "     S := if expr then S else S\n",
    "     S := stmt\n",
    "</pre>    \n",
    "\n",
    "(b) Now consider the following, more complicated grammar, which is NOT ambiguous:\n",
    "<pre>\n",
    "    S :=  M\n",
    "    S := U\n",
    "    M := if expr then M else M\n",
    "    M := stmt\n",
    "    U := if expr then S\n",
    "    U := if expr then M else U\n",
    "</pre>\n",
    "(M representes \"matched then's\" and U representes \"unmatched then's.\"\n",
    "Show the parse tree for the dangling-else example from (a) using this new grammar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "<pre>\n",
    "Your answer here\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Three (10 pts)\n",
    "\n",
    "For each of the following either give some proof/argument/intuition as to why it is true, or give a counter-example showing it is not true. If it is true, an example may illustrate the intuition, but is not sufficient by itself. \n",
    "\n",
    "<p>Let $G$ be a grammar and $w$ be a string of terminal symbols.\n",
    "\n",
    "<ol style=\"list-style-type: lower-alpha;\">\n",
    "      <li> If each rule in $G$ has most one non-terminal on the right-hand side, then any left-most derivation of a string $w$ is also a right-most derivation. \n",
    "      <li> $G$ is ambiguous if and only if there are two different right-most derivations of some string $w$. \n",
    "      <li> If there are two distinct derivations (of any kind) of $w$ in $G$, then $G$ is ambiguous. \n",
    "      <li> If $G$ is not ambiguous, then every derivation of $w$ in $G$ will have the same number of derivation steps (those indicated by => in the derivations). \n",
    "      <li> If $G$ is ambiguous, then there are an infinite number of strings $w$ each of which has more than one parse tree.  \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "<pre>\n",
    "Your answer here\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Four  Parser (20 pts)\n",
    "\n",
    "Here is the grammar similar to the one discussed in lecture for the language of arithmetic expressions (we have added a rule for parenthesized expressions):\n",
    "<pre>\n",
    "0:   S := E $\n",
    "1:   E := E + T\n",
    "2:   E := T\n",
    "3:   T := T * F\n",
    "4:   T := F\n",
    "5:   F := ( E )\n",
    "6:   F := int\n",
    "\n",
    "</pre>\n",
    "\n",
    "In the rest of this problem, you will add code to build a shift-reduce parser for this grammar. The transition table is given, and you have to supply code to complete the parser. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexer Code: Insert your lexer code in this next cell (or use my posted solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert your lexer here or use my solution (posted Friday am)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Code (do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The symbols of the\n",
    "# terminals are encoded by pairs (category,etc) according to:\n",
    "\n",
    "ident = 0           # not used in this hw, but leave it in for the future!\n",
    "integer = 1\n",
    "floating = 2        # not used in this hw\n",
    "plus = 3\n",
    "minus = 4           # not used in this hw\n",
    "mult = 5\n",
    "div = 6             # not used in this hw\n",
    "lparen = 7\n",
    "rparen = 8\n",
    "comma = 9           # not used in this assignment\n",
    "error = 10        \n",
    "\n",
    "# Non-terminals are encoded as pairs using these codes:\n",
    "\n",
    "S = 11             # these will be represented as tuples, e.g., (S,), just like terminals\n",
    "E = 12\n",
    "T = 13\n",
    "F = 14\n",
    "\n",
    "# special token for end of input\n",
    "\n",
    "end_of_input = 15       # (end_of_input,) will be pretty-printed as ($,)\n",
    "\n",
    "\n",
    "# pretty-printing lists of tokens\n",
    "\n",
    "tokenCats = ['ident','integer','floating','plus','minus','mult','div',\n",
    "             'lparen','rparen','comma','error','S','E','T','F','$']\n",
    "\n",
    "def tokenToString(t):\n",
    "    if t == None:\n",
    "        return str(t)\n",
    "    elif t[0] < 3:\n",
    "        return '(' + tokenCats[t[0]] + ',' + str(t[1]) + ')'\n",
    "    else:\n",
    "        return '(' + tokenCats[t[0]] + ',)'\n",
    "        \n",
    "def tokenListToString(lst):\n",
    "    res = '[ '\n",
    "    for t in lst[:-1]:\n",
    "        res = res + tokenToString(t) + ', '\n",
    "    res = res + tokenToString(lst[-1]) + ' ]'\n",
    "    return res\n",
    "\n",
    "# pretty-printing parser configurations\n",
    "\n",
    "def pprintParser(parsingStack,inputListOfTokens):\n",
    "    totalWidth = 80\n",
    "    smallestGap = 6\n",
    "    largestStackLength = int(totalWidth*0.6 - smallestGap/2)   # most characters to display\n",
    "    largestInputLength = totalWidth - largestStackLength - smallestGap\n",
    "    \n",
    "    p = '| '\n",
    "    for symbol in parsingStack:\n",
    "        p = p + tokenToString(symbol) + ' '\n",
    "    if len(p) > largestStackLength:\n",
    "        ind = int(len(p) - largestStackLength + 9)\n",
    "        p = '| ... ' + p[ind:]\n",
    "        \n",
    "    q = \"\"\n",
    "    for tok in inputListOfTokens[:-1]:\n",
    "        q = q + tokenToString(tok) + ' '\n",
    "    if len(inputListOfTokens) > 0:\n",
    "        q = q + tokenToString(inputListOfTokens[-1]) \n",
    "\n",
    "    if len(q) > largestInputLength:\n",
    "        ind = int(largestInputLength - 9)\n",
    "        q = q[:ind] + ' ... ' \n",
    "    \n",
    "    q = q + ' |'\n",
    "        \n",
    "    p = p + (' ' * (totalWidth - len(p) - len(q)))\n",
    "    print(p+q)\n",
    "\n",
    "# pretty-printing rules\n",
    "\n",
    "def toStringRule(r):\n",
    "    s = tokenCats[r[0][0]] + ' := '\n",
    "    for t in r[1]:\n",
    "        s = s + tokenCats[t[0]] + ' '\n",
    "    return s\n",
    "                          \n",
    "def toStringRules(lst): \n",
    "    s = \"\"\n",
    "    for r in lst:\n",
    "        s = s + toStringRule(r) + '\\n'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (A): Encoding the rules\n",
    "\n",
    "Rules will be represented by pairs (lhs, rhs) where lhs is a single non-terminal tuple\n",
    "and rhs is a list of tuples for terminals or non-terminals. For example, the start\n",
    "rule would be represented as follows:\n",
    "<pre>\n",
    "((S,),[(E,),(end_of_input,)])\n",
    "</pre>\n",
    "and the last rule would be\n",
    "<pre>\n",
    "((F,),[(integer,)])\n",
    "</pre>\n",
    "In this last rule, you don't actually need the value of the integer token (only the category of token\n",
    "is used during parsing), so you can just leave it out. \n",
    "\n",
    "In the next cell, encode the list of rules in the order given above. This will be useful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules = [      ]                    \n",
    "\n",
    "\n",
    "\n",
    "print(\"Grammar:\\n\\n\" + toStringRules(rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Implement the DFA\n",
    "\n",
    "<p> Here is a diagram of the DFA which will be used to read the stack and decide \n",
    "when to do reduce moves. The error state (numbered -100) is implicit. \n",
    "\n",
    "![DFA](http://www.cs.bu.edu/fac/snyder/cs320/Homeworks/HW02Diagram.jpg \"DFA\")\n",
    "\n",
    "We have provided the DFA in the next cell in the form of a transition table. You must complete the definition of the action to be taken when the DFA is applied to the parsing stack plus the \"lookahead\" symbol (next symbol in the input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# transition table   DO NOT MODIFY UNLESS YOU REALLY KNOW WHAT YOU ARE DOING!\n",
    "\n",
    "# special actions used by the parser\n",
    "\n",
    "err = -100\n",
    "accept = 100\n",
    "\n",
    "table = { 1: { 1:6, 2:err, 3:err, 4:err, 5:err, 6:err, 7:9, 8:err, 9:err, 10:err, 11:err, 12:2, 13:4, 14:13, 15:err}, \n",
    "          2: { 1:err, 2:err, 3:8, 4:err, 5:err, 6:err, 7:err, 8:err, 9:err, 10:err, 11:err, 12:err, 13:err, 14:err, 15:accept}, \n",
    "          3: { 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0, 10:0, 11:0, 12:0, 13:0, 14:0, 15:0}, \n",
    "          4: { 1:-2, 2:-2, 3:-2, 4:-2, 5:5, 6:-2, 7:-2, 8:-2, 9:-2, 10:-2, 11:-2, 12:-2, 13:-2, 14:-2, 15:-2}, \n",
    "          5: { 1:6, 2:err, 3:err, 4:err, 5:err, 6:err, 7:9, 8:err, 9:err, 10:err, 11:err, 12:err, 13:err, 14:12, 15:err}, \n",
    "          6: { 1:-6, 2:-6, 3:-6, 4:-6, 5:-6, 6:-6, 7:-6, 8:-6, 9:-6, 10:-6, 11:-6, 12:-6, 13:-6, 14:-6, 15:-6}, \n",
    "          7: { 1:-1, 2:-1, 3:-1, 4:-1, 5:5, 6:-1, 7:-1, 8:-1, 9:-1, 10:-1, 11:-1, 12:-1, 13:-1, 14:-1, 15:-1}, \n",
    "          8: { 1:6, 2:err, 3:err, 4:err, 5:err, 6:err, 7:9, 8:err, 9:err, 10:err, 11:err, 12:err, 13:7, 14:13, 15:err}, \n",
    "          9: { 1:6, 2:err, 3:err, 4:err, 5:err, 6:err, 7:9, 8:err, 9:err, 10:err, 11:err, 12:10, 13:4, 14:13, 15:err}, \n",
    "         10: { 1:err, 2:err, 3:8, 4:err, 5:err, 6:err, 7:err, 8:11, 9:err, 10:err, 11:err, 12:err, 13:err, 14:err, 15:err}, \n",
    "         11: { 1:-5, 2:-5, 3:-5, 4:-5, 5:-5, 6:-5, 7:-5, 8:-5, 9:-5, 10:-5, 11:-5, 12:-5, 13:-5, 14:-5, 15:-5},\n",
    "         12: { 1:-3, 2:-3, 3:-3, 4:-3, 5:-3, 6:-3, 7:-3, 8:-3, 9:-3, 10:-3, 11:-3, 12:-3, 13:-3, 14:-3, 15:-3},\n",
    "         13: { 1:-4, 2:-4, 3:-4, 4:-4, 5:-4, 6:-4, 7:-4, 8:-4, 9:-4, 10:-4, 11:-4, 12:-4, 13:-4, 14:-4, 15:-4}}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this reads a list of tokens (i.e., the parsing stack) and returns the state where you end up\n",
    "\n",
    "def action(lst,table):\n",
    "    pass \n",
    "\n",
    "\n",
    "# TESTS\n",
    "# You may not modify the following in any way\n",
    "# All tests should return True\n",
    "\n",
    "print(action([(lparen,)],table)==9)\n",
    "print(action([(E,),(plus,), (F,)],table) == 13)\n",
    "print(action([(error,),(E,)],table) == err)\n",
    "print(action([(lparen,),(lparen,),(lparen,),(lparen,)],table)== 9)\n",
    "print(action([(lparen,),(lparen,),(E,),(rparen,),(plus,)],table) == -5)\n",
    "print(action([(E,),(end_of_input,)],table) == accept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Implement the driver for the parser\n",
    "\n",
    "Most of this has been done, just complete where you see pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# parse takes a list of tokens and determines if it is a \n",
    "# well-formed arithmetic expression.\n",
    "\n",
    "def parse(list_of_input_tokens,rules,table,verbose=False):\n",
    "    \n",
    "    # add end_of_input marker to input\n",
    "    pass\n",
    "    \n",
    "    # input stack; use pop(0) to remove front item in list\n",
    "    input_stack = list_of_input_tokens\n",
    "    \n",
    "    # parsing stack; use append to push onto end and pop() to pop from end\n",
    "    parsing_stack = []\n",
    "    \n",
    "    if verbose:\n",
    "        print('Input Tokens: ' + tokenListToString(input_stack) + '\\n')\n",
    "        pprintParser(parsing_stack,input_stack) \n",
    "    \n",
    "    while( len(input_stack) > 0 ):\n",
    "        \n",
    "        # Now we will \"lookahead\" at the next symbol on the input and ask the automaton what to do\n",
    "        # a positive number means to shift, and a negative number -n means to reduce by rule n\n",
    "        \n",
    "        # complete this next line by calling action on the parsing stack plus the\n",
    "        # next symbol on the input\n",
    "        \n",
    "#        n = \n",
    "        if n == accept:   # reduce by start rule, success\n",
    "            if verbose:\n",
    "                pprintParser(parsing_stack,input_stack)\n",
    "            return True\n",
    "        elif n == err:     #  problem on stack!\n",
    "            if verbose:\n",
    "                pprintParser(parsing_stack,input_stack)\n",
    "            return False \n",
    "        elif n > 0:     # shift          \n",
    "            pass         \n",
    "        else:         # reduce by rule -n            \n",
    "            pass\n",
    "   \n",
    "        if verbose:\n",
    "            pprintParser(parsing_stack,input_stack)\n",
    "            \n",
    "    return None     # this will never be executed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parser Tests \n",
    "\n",
    "Last two are incorrect and will return False, rest are correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b12d94bd581c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lexer' is not defined"
     ]
    }
   ],
   "source": [
    "# Test 1: Correct parse\n",
    "\n",
    "s = '2'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3f45659fad23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(2 + 4)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lexer' is not defined"
     ]
    }
   ],
   "source": [
    "s = '(2 + 4)'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f7c7f696a88f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2+4*8+5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lexer' is not defined"
     ]
    }
   ],
   "source": [
    "s = '2+4*8+5'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ebf92368a4e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'((2 + (4)) + 4)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lexer' is not defined"
     ]
    }
   ],
   "source": [
    "s = '((2 + (4)) + 4)'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b4580596ae30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2 * 5 + 2 * 2 + 4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lexer' is not defined"
     ]
    }
   ],
   "source": [
    "s = '2 * 5 + 2 * 2 + 4'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8a817d60e424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(2 + )'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lexer' is not defined"
     ]
    }
   ],
   "source": [
    "s = '(2 + )'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-df9d29860e2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(2 + 4.5)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lexer' is not defined"
     ]
    }
   ],
   "source": [
    "s = '(2 + 4.5)'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
